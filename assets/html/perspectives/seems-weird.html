<div class="page-data" data-page-title="Seems weird"></div><p>On its face, it can seem like science fiction to imagine machines “actually thinking.” Some people feel that this should count as evidence against the idea: If an idea seems weird, there’s probably something wrong with it.</p>
<p>It’s undeniable that the prospect of a generally capable system like a “CEO AI” seems quite far-fetched. As with all extraordinary claims, it’s reasonable to want to see extraordinary evidence.</p>
<p>There are a few things to say about this:</p>
<ul><li>The more dangerous an outcome, the less evidence you should need to be wary of it. If you hear a rumor that opening a door in an acquaintance’s house leads to a crossbow behind that door shooting an arrow at your head, this would be a very bizarre situation, but how sure would you have to be to not open the door? You might err on the side of not opening the door, even if you think it’s unlikely the crossbow is really there.</li>
<li>Regarding advanced AI systems feeling ‘weird’, there are reasons to think that any possible outcome of the next 50-100 years of history will be quite weird. It’s uncontroversial to say that change in general has been happening more quickly throughout history, and all “weird” means is “different and unexpected.” In fact, we should expect the future to be weird; most people would agree that people 100 years ago would think our present is weird. So it’s very likely the future will seem weird to us.All that remains to be discussed is what form the weirdness will take. Indeed, there are reasons to think that this century might be a special one in the history of humanity. This argument is outlined <a href='https://www.cold-takes.com/most-important-century/#Summary' target='_blank'>in the “most important century” blog post series</a> by Holden Karnofsky.</li>
<li>Given this, it’s reasonable to think this weirdness will be related in some way to AI. The amount of resources invested into AI is increasing rapidly, meaning that the most transformative AI advances may still be ahead of us. See this <a href='https://ourworldindata.org/ai-investments' target='_blank'>report looking at the amount of resources invested in AI research for details.</a> <li>In a <a href='https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/#Summary_of_results' target='_blank'>2022 survey of AI researchers</a>, the aggregate forecasted time until human-level AI was 37 years (2059).</li>
<li>A <a href='https://www.cold-takes.com/are-we-trending-toward-transformative-ai-how-would-we-know/#surveying-experts' target='_blank'>survey from 2017</a> asked for ““when unaided machines can accomplish every task better and more cheaply than human workers" and got 20% probability by 2036, 50% by 2060, and 70% by 2100.</li></li>
<li>As an aside, there’s a common preconception that there’s already been a long history of unjustified hype for AI capabilities. One could argue that ‘AGI alarmism’ is just part of that trend. However, <a href='https://www.openphilanthropy.org/research/what-should-we-learn-from-past-ai-forecasts/' target='_blank'>a recent study</a> suggests there actually hasn’t been as much unjustified hype as the common perceptions would suggest. This should reduce one’s inclination to treat the current concerns over AI as overblown.</li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
