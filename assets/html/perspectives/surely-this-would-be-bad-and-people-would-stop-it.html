<div class="page-data" data-page-title="People would stop this"></div><p>It is difficult to stop something that has the potential to be highly financially successful, is decentralized on an international level, has economic momentum, and for which certain segments of the population may resist efforts to be stopped. These conditions seem to apply to AI.</p>
<p>Consider:</p>
<ul><li>The difficulty of transitioning the world to new energy sources.</li>
<li>How could Bitcoin be stopped worldwide?</li>
<li>How could all nuclear weapons in the world be disarmed? Surely this is an easier problem than eradicating AI, because all nuclear weapons are obviously harmful—unlike AI, which can have incredible benefits.</li>
<li>How successful have we been in stopping the COVID-19 pandemic?</li>
</ul><p>These are all difficult collective action problems, and some of them are easier than stopping AI development from occurring in several countries simultaneously.</p>
<p>Consider also: Policymakers are very busy, have competing priorities and constituents, and know much less about AI than technical researchers.</p>
<ul><li>What actions do you think policymakers should take ideally? If policymakers didn’t know how to regulate AI, what actions would you convey to them, given that their technical expertise, time, and attention are limited?</li>
<li>Historically, technology moves much faster than government. How quickly do you expect policymakers will be able to make changes, and what kind of changes will work well with rapidly-changing technology or unexpected breakthroughs?</li>
<li>International coordination might be required to avoid an arms race towards increasingly sophisticated AI. National interests often favor rapid technology development. What do we think of the current policy situation with respect to international competition on AI, how do we expect it to develop, and how should it develop?<br/></li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
