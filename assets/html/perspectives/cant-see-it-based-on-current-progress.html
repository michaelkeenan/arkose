<div class="page-data" data-page-title="Can’t see it based on current progress"></div>
<blockquote><p>
In answering your question, I don't think it will necessarily diverge, we'll just hit a roadblock and we're already hitting them. You've heard about AlexNet like 10 years ago, and now, sure, we have cute applications and like filters on the phone, but like, did AI actually enter your life, daily life? Well, not true, I mean, you have a better phone, they're more capable, but actually AI, like in terms of that we all dream about, does it enter your life? Well, not really. We can live without it, right? So, we're already hitting all these roadblocks, even in medical applications. 10 years ago Google claimed they'd solved, like, skin cancer, when they can detect it, and it didn't... It didn't really see the light of day except for some hospitals in India, unfortunately. So we're already hitting tons of roadblocks, and I don't think it's... It's like for this reason precisely, because when you face reality, you just don't work as well as you expect for multiple reasons. 
</p></blockquote>


<blockquote><p>
[ Interviewer: “We have been working on AI for under 100 years, and we are on an exponential trend in terms of human technological development. 10,000 years ago, not much changed from lifetime to lifetime, and now things change extremely quickly.”] I would challenge your exponential argument. I agree that a lot of things in our world are exponential, but progress in many fields hasn't been. But I guess what I was going to say is like for example, life expectancy hasn't been growing. You could have looked at that and it was flat and then it blew up, I don't know, early 1900s maybe. But it's plateaued. You could look at Moore's Law, it's starting to die. I think all those arguments pre-suppose that this sort of exponential growth continues and I don't know if I agree with that baseline assumption. Yeah, I guess, I think the logic that all of us have is like, "Yeah, we will continue to have faster computers, we'll continue to have newer technologies." But I just don't know if that's true. Yeah, [person] often says all these things, it's like 50 years until infinity, that's the range, and I think that's true. It could be anywhere there. It's hard to put a number to it. And yeah, I don't know. Again, I just challenge the assumption of the base. I just don't see, for example, like computing power continuing to grow. There's fundamental limits to it, both in the quantum side and the classical side. 
</p></blockquote>

<p>While current systems may not be considered generally intelligent, they do possess capabilities that are quite impressive, considering that they have not yet reached the level of AGI. For example:</p>

<ul><li>PaLM (2022) <a href='https://ourworldindata.org/grapher/ai-training-computation?time=2017-08-04..2022-07-01' target='_blank'>was the most compute intensive model ever trained at the time of release</a>. This model achieved state-of-the-art few-shot performance across numerous difficult NLP tasks, including natural language inference, common-sense reasoning, in-context reading comprehension, and answering questions. It is also able to explain novel jokes.</li>
</ul><p><figure><img src='/aird/assets/images/arguments/9A36C1759D7EA7B70A424A7E6D4EDA0A.png' referrerpolicy='no-referrer'/><figcaption markdown='1'>PaLM’s capabilities expansion as a function of model size. Note that new capabilities appear suddenly as the model grows.
</figcaption></figure></p>
<p><figure><img src='/aird/assets/images/arguments/22C55F4C3CFD67F74FEC6CA19DB7F56E.png' referrerpolicy='no-referrer'/><figcaption markdown='1'>Explaining Jokes using PaLM (2-shot). Source: <a href='https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf' target='_blank'>Google</a>.
</figcaption></figure></p>
<ul><li>Importantly, simply scaling the model, without incorporating new insights or understanding, resulted in significant changes in its capabilities. PaLM gained abilities like explaining jokes and answering physics questions without anyone understanding how the human brain does them.</li>
</ul><li>Dall-E 2 shows creativity and the ability to understand concepts.</li>
<li><figure><img src='/aird/assets/images/arguments/3D83536B320986F415E1552745DEBFA6.png' referrerpolicy='no-referrer'/><figcaption markdown='1'>Dall-E 2 samples. Source: <a href='https://cdn.openai.com/papers/dall-e-2.pdf' target='_blank'>OpenAI</a> 
</figcaption></figure></li>
<li>A <a href='https://www.deepmind.com/blog/generally-capable-agents-emerge-from-open-ended-play' target='_blank'>2021 Deepmind paper</a> describes agents with emergent generalized skills on novel tasks. The agents were trained on a variety of tasks in a virtual environment, then performed well in novel games they’d never encountered.</li>

<p>Furthermore, though we have not achieved AGI yet, there are good reasons to think we could get there eventually:</p>

<ol><li>There is a long history of people mistakenly believing possible things to be impossible. Consider these examples:</li>
<ol><li>Just two years before the first flight of the Wright Brothers, Wilbur Wright—by his own account—predicted flight was at least fifty years away.</li>
<li>In 1933, Ernest Rutherford declared that the idea of harnessing atomic energy was “moonshine.” Shortly thereafter—the very next day, according to some accounts - Leo Szilard discovered the possibility of a nuclear chain reaction.</li>
<li>In 1939, Enrico Fermi proclaimed that the chain reaction was just a “remote possibility”—four years later, Fermi himself oversaw the world’s first nuclear reactor.</li>
<li>In an informal review, <a href='https://www.cold-takes.com/the-track-record-of-futurists-seems-fine/' target='_blank'>predictions of the “Big Three” science fiction writers</a> of the 20 th century were categorized and evaluated, and only 31% of their predictions turned out to be correct.</li>
</ol><li>Many people did not anticipate the amount of progress that has been made during the deep learning revolution, and progress seems to still be accelerating.</li>
<ol><li>For example, <a href='https://bounded-regret.ghost.io/ai-forecasting/' target='_blank'>predictions made by experienced forecasters in 2021</a> about AI progress on state-of-the-art accuracy on the MATH and Massive Multilanguage Understanding datasets were wildly inaccurate. <a href='https://bounded-regret.ghost.io/ai-forecasting-one-year-in/' target='_blank'>Actual improvement after one year was much higher than predicted</a>. These forecasts were commissioned by researcher Jacob Steinhardt.</li>
</ol><li>There has been a significant investment of resources - including time, money, and people - in AI. <a href='https://venturebeat.com/ai/report-ai-investments-see-largest-year-over-year-growth-in-20-years/' target='_blank'>This includes a significant increase in investment since 2010 due to international economic interests.</a>.</li>
<li>Evolution produced intelligence in a pretty “dumb” way: it arose as a byproduct of biological agents roaming in a complex environment and competing for fitness advantage.</li>
</ol>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
