<div class="page-data" data-page-title="Work not urgent currently"></div>
<blockquote><p>
 So... I trust the people that I work with to kind of hit the button when it really needs to be hit. Because right now, like I said, I think people don't take it seriously, partly because I don't think they really believe it needs to be taken seriously. These researchers are not saying, "Oh my God, we need to take this seriously, but I've got other stuff to do." They really are just like, I don't think we're at that stage where we need to take it seriously. I think the people that I work with are, on the most part-- mostly pretty well-intentioned people. There's some disagreement over this. [...] I know that within OpenAI there were some healthy discussions about what is the correct deployment model for things like GPT-3. All the discussions that I've had so far give me a lot of confidence that these people aren't stupid and they're not entirely negligent. I think they're possibly occasionally overconfident, but they're not arrogant, if that makes any sense. As in like, they know they're fallible. They don't always put the right error bars on their decisions, but they know they're not infallible. Ultimately, that's what it's going to come down to. There's not, like, a system for this. It's going to be a few hundreds to a thousand-- thousand people, doing the sensible thing. For the moment, it looks like that's going to happen. But... I agree that that isn't entirely confidence-inspiring. But I think that's going to be the way it goes. 
</p></blockquote>


<blockquote><p>
I believe [the problems] will be resolved in the future. 
</p></blockquote>

<p>Counter-arguments:</p>
<ul><li>Even if our timelines are 50+ years, who knows how long this is going to take? If it turns out to be a 20-year project, then we need to start at least 20 years before the development of AGI.</li>
<li>If there is something reasonably useful we can do now, why not do it now?</li>
<li>It is unclear how much we would gain by waiting for different AI approaches to develop and then doing alignment.</li>
<li>It is quite likely that present-day alignment work will inform future alignment work even in new paradigms.</li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
