---
layout: argument
title: "Humans have alignment problems too"
breadcrumbs: The Alignment Problem:the-alignment-problem,Humans have alignment problems too:humans-have-alignment-problems-too
---

<blockquote><p>
Let's say we are so worried that autonomous cars today can lead to some crashes or something, but today on record, human error or human misjudgment causes much more fatal issues on the road than potentially any AI driven car today. 
</p></blockquote>


<blockquote><p>
Humans fail at their tasks all the time, humans make errors all the time, so if we have a system that has an error threshold that's still better than humans, can we be angry? We can't do any better. Keeping everything else the same, if the decision system that we have fails less than humans, then sure, we don't want to be failing, we want to be perfect, but we can't really complain. It is a situation that we'll have to work at, but that's like everything. There's always room for improvement. 
</p></blockquote>

<ul><li>Humans have a shared evolutionary prior about basic morality and norms of behavior, which AI would lack. Therefore, if an AI is optimizing over all potential future realities in some sense, it might end up in a really alien part of that space—alien to humans, because it’s optimizing over a really large space. This space will by necessity contain motivations and actions that seem totally alien to us.</li>
<li>Present-day AIs sometimes find solutions to problems that humans would never think of. So it’s plausible that what an AI does will seem pretty alien and uncommon—which makes it more difficult to reason about.</li>
<li>AI can duplicate quickly, and a collection of duplicated AIs may be able to collaborate perfectly.</li>
<li>AI could be much more powerful than any one human, or even all humans together. The case for this is outlined in <a href='https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/' target='_blank'>AI Could Defeat All Of Us Combined</a> by Holden Karnofsky.</li>
<li>AI could also act much more quickly than humans.</li>
<li>It’s fine if your child isn’t perfectly aligned with you, because they are their own person and they have autonomy. People are just pretty easy to control overall—as we understand human psychology, and we all have very roughly the same limitations and boundaries in society. If the AI isn’t aligned with humanity and gets out of control, it could be quite dangerous.</li>
<li>We have institutions to regulate human conflicts. But governance takes a really long time to develop and won’t keep up with tech progress.</li>
<li>If we acknowledge that far-greater-than-human-intelligence is possible, then a being with that level of intelligence would be much more powerful than humans and could circumvent the usual checks and balances that mostly prevent misaligned humans from doing very bad things.</li>
<li>AGI could be so useful that humans give it great power and responsibility, more than is commonly given to individual humans.</li>
<li>Human misuse can be a big problem. At some point though, we might have an AI agent, which is smarter than any human, trying to optimize the world. And that would be dangerous above and beyond misuse scenarios. <a href='./misuse-is-a-bigger-problem' >See also our section on misuse</a></li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
